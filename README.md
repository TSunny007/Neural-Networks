# Neural-Networks


## Gradient Descent:

The objective here is to understand the Gradient Descent mechanism that goes on in Neural Networks by working with basic examples. Important learning concepts here are basic synapse mechanisms and back-propagation. 

[Simple Gradient Descent Perceptron](https://nbviewer.jupyter.org/github/TarunSunkaraneni/Neural-Networks/blob/master/Gradient%20Descent/Simple%20Gradient%20Descent%20Perceptron.ipynb)

[Optimized Gradient Descent](https://nbviewer.jupyter.org/github/TarunSunkaraneni/Neural-Networks/blob/master/Gradient%20Descent/Optimized%20Gradient%20Descent%20Neural%20Net.ipynb)

---

## Learning Neural Networks and Deep Learning:

This is closely followed by a [Udemy Class](https://www.udemy.com/deeplearning/learn/v4/overview).
Datasets are obtained from [Here](https://www.superdatascience.com/deep-learning/)

[Bank Customer Classification using an Atrificial Neural Network(ANN)](https://nbviewer.jupyter.org/github/TarunSunkaraneni/Neural-Networks/blob/master/Deep_Learning/Supervised%20Deep%20Learning/Artificial%20Neural%20Networks%20%28ANN%29/ANN/Notebook/ANN_Bank_Customer_Classification.ipynb): The "Vanilla" Neural Nets. They are the most basic type of Deep Learning algorithms. Designed to mimic the processes in the human brain, they create a facility for a machine to learn instead of being hard-coded what to do. Artificial Neural Networks are a type of Supervised Learning Algorithm. Some key concepts covered here are Backward propogation, some reinforced learning techniques, activation functions, input, hiden and output layers, k-fold validation, neuron droupouts, and parameter tuning using Gridsearch.
