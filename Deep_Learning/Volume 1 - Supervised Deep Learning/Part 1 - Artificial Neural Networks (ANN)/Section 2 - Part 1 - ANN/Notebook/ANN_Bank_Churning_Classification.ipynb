{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import theano\nimport tensorflow\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['Churn_Modelling.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "585b837081b2731852cc2efa6a76b41a0b3d9aa8"
      },
      "cell_type": "markdown",
      "source": "# Data Preprocessing "
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing the dataset\ndataset = pd.read_csv('../input/Churn_Modelling.csv')\nX = dataset.iloc[:,3:13].values\ny = dataset.iloc[:, 13].values",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4272911d807e30489b3054c10e03224626bc385"
      },
      "cell_type": "code",
      "source": "# Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany\n# This will convert those strings into scalar values for analysis\nprint(X[:8,1], '... will now become: ')\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabel_X_country_encoder = LabelEncoder()\nX[:,1] = label_X_country_encoder.fit_transform(X[:,1])\nprint(X[:8,1])",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['France' 'Spain' 'France' 'France' 'Spain' 'Spain' 'France' 'Germany'] ... will now become: \n[0 2 0 0 2 2 0 1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3439cd590ff1e59ab284a54b501138dd839d55b2"
      },
      "cell_type": "code",
      "source": "# We will do the same thing for gender. this will be binary in this dataset\nprint(X[:6,2], '... will now become: ')\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabel_X_gender_encoder = LabelEncoder()\nX[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\nprint(X[:6,2])",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['Female' 'Female' 'Female' 'Female' 'Female' 'Male'] ... will now become: \n[0 0 0 0 0 1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "caf64452023dc5c5efb7047f6eede1ba7b4ba3fd"
      },
      "cell_type": "markdown",
      "source": "The Problem here is that we are treating the countries as one variable with ordinal values (0 < 1 <  2). Therefore, one way to get rid of that problem is to split the countries into respective dimensions. that is,\n\n| Country |  -> | Country|-> |Spain|France|Germany|\n|------|      |------|  |------|    |------|    |------|\n|   Spain |   -> |0| -> |1|0|0|\n|   France | -> |1| -> |0|1|0|\n|   France | ->  |1| -> |0|1|0|\n|   Germany | -> |2| -> |0|0|1|"
    },
    {
      "metadata": {
        "_uuid": "43452ef2a058802c2fb8e1d1a4f128d553fe6bb7"
      },
      "cell_type": "markdown",
      "source": "\nGender doesn't need to go through a similar process becasue it is binary"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c713a1181e4303184f6ab6d778c5d607f258c7bd"
      },
      "cell_type": "code",
      "source": "# Converting the string features into their own dimensions. Gender doesn't matter here because its binary\ncountryhotencoder = OneHotEncoder(categorical_features = [1]) # 1 is the country column\nX = countryhotencoder.fit_transform(X).toarray()",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e09c545d41c0683b9261741c2c02150bad11e5d"
      },
      "cell_type": "code",
      "source": "X",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n        1.0000000e+00, 1.0134888e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,\n        1.0000000e+00, 1.1254258e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n        0.0000000e+00, 1.1393157e+05],\n       ...,\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n        1.0000000e+00, 4.2085580e+04],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n        0.0000000e+00, 9.2888520e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n        0.0000000e+00, 3.8190780e+04]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "602fb3a106749205fe025a0eaa8233cc0df20921"
      },
      "cell_type": "markdown",
      "source": "You can now see that the first three columns represent the three countries that constituted the \"country\" category. We can now observe that  we essentially only need two columns: a 0 on two countries means that the country has to be the one variable which wasn't included. This will save us from the problem of using too many dimensions\n\n|Spain|France|Germany|-> |France|Germany|\n |------|    |------|    |------|     |------|     |------|\n |1|0|0|-> |0|0|\n|0|1|0|-> |1|0|\n|0|1|0|-> |1|0|\n|0|0|1|-> |0|1|"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d82b73942937f786b623b12bdf3780622802c010"
      },
      "cell_type": "code",
      "source": "X = X[:,1:] # Got rid of Spain as a dimension. It is still there through out inferences",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "16837320dfc1755aee8651e1aa87380661d73766"
      },
      "cell_type": "code",
      "source": "# Splitting the dataset into the Training and Testing set.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8426862d205a1dbc7f0adf221e523c66eb62254d"
      },
      "cell_type": "markdown",
      "source": "Feature scaling is a method used to standardize the range of independent variables or features of data. It is basically scaling all the dimensions to be even so that one independent variable does not dominate another. For example, bank account balance ranges from millions to 0, whereas gender is either 0 or 1. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41267ac3793d68c31781decf9350565e040e4f57"
      },
      "cell_type": "code",
      "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f4bd478642b6abace86cc3c366f605c68af8a17"
      },
      "cell_type": "code",
      "source": "X_train",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n        -1.03227043,  1.10643166],\n       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n         0.9687384 , -0.74866447],\n       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n        -1.03227043,  1.48533467],\n       ...,\n       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n        -1.03227043,  1.41231994],\n       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n         0.9687384 ,  0.84432121],\n       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n        -1.03227043,  0.32472465]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c5381130b2a66f00b80620e861c8dff9069bd874"
      },
      "cell_type": "markdown",
      "source": "## END OF PREPROCESSING"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}